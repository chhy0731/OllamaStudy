{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd72a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from langchain_ollama import OllamaLLM\n",
    "llm = OllamaLLM(model=\"gemma3:12b\")\n",
    "\n",
    "os.environ['SERPAPI_API_KEY'] = 'serpapi key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3ef740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "params = {\n",
    "    \"engine\" : \"google_news\", \n",
    "    \"gl\": \"KR\",\n",
    "    \"hl\": \"ko\",\n",
    "}\n",
    "search = SerpAPIWrapper(params=params)\n",
    "\n",
    "search.run(\"이차전지 산업\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d37491",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = search.run(\"이차전지 산업\")\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba14e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a6b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = results[0]['link']\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d96fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()\n",
    "\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa326efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_longest_text(text):\n",
    "    segments = text.split('\\n')\n",
    "    longest_segment = max(segments, key=len)\n",
    "    \n",
    "    return longest_segment\n",
    "\n",
    "text = docs[0].page_content\n",
    "\n",
    "longest_text = extract_longest_text(text)\n",
    "print(\"가장 긴 텍스트:\\n\", longest_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f14cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time \n",
    "\n",
    "new_results = []\n",
    "for result in tqdm(results):\n",
    "    try:\n",
    "        url = result['link']\n",
    "        loader = WebBaseLoader(url)\n",
    "        docs = loader.load()\n",
    "        text = docs[0].page_content\n",
    "        longest_Text = extract_longest_text(text)\n",
    "        result['content']= longest_text\n",
    "        new_results.append(result)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"새로운 결과 개수 : \", len(new_results))\n",
    "new_results[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.DataFrame(new_results)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6baee4",
   "metadata": {},
   "source": [
    "## 뉴스 요약 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea288504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "#promopt\n",
    "prompt_template = \"\"\"다음 내용을 한국어(한글)로 간결하게 요약하라.\n",
    "\n",
    "규칙:\n",
    "- 요약 내용만 출력한다\n",
    "- 영어 문장, 설명, 인사말을 포함하지 않는다\n",
    "- 불필요한 문구 없이 바로 요약문만 작성한다\n",
    "\n",
    "내용:\n",
    "{text}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "#LLM\n",
    "llm = OllamaLLM(model=\"gemma3:12b\")\n",
    "\n",
    "#parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "llm_chain = prompt | llm | output_parser\n",
    "\n",
    "response = llm_chain.invoke({\"text\": data['content'][0]})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c824c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_news(content):\n",
    "    response = llm_chain.invoke({\"text\": content})\n",
    "    return response\n",
    "\n",
    "df_test = data.head(3)\n",
    "df_test['summary'] = df_test['content'].apply(summarize_news)\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d632e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['content', 'summary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1488cbd",
   "metadata": {},
   "source": [
    "## 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbe05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "#prompt\n",
    "prompt_template = \"\"\"Please extract 3 key words form the following content in Korean Hangul(한글) and separate them with commas (,) \n",
    "\"{text}\" \n",
    "Key words :\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "#LLM \n",
    "llm = OllamaLLM(temperature = 0, model=\"gemma3:12b\")\n",
    "\n",
    "#ouput parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "#Chain\n",
    "llm_chain = prompt | llm | output_parser\n",
    "\n",
    "response = llm_chain.invoke({\"text\": data['content'][0]})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 본문을 입력으로 사용하여 핵심 키워드를 추출하는 함수 \n",
    "def extract_keywords(content):\n",
    "    response = llm_chain.invoke({\"text\": content})\n",
    "    return response\n",
    "\n",
    "#결과 확인 - 테스트를 위해서 첫 3행만 별도로 추출하여 추출 \n",
    "df_test['keywords'] = df_test['content'].apply(extract_keywords)\n",
    "\n",
    "df_test[['content', 'summary' , 'keywords']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc77798",
   "metadata": {},
   "source": [
    "## 뉴스 카테고리 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a1c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "\n",
    "#prompt \n",
    "prompt_template = \"\"\"Based on the following content, please classify the news into the approproiate category and provide the category name in Korean without description:\n",
    "\"{text}\"\n",
    "News Category:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "#LLM \n",
    "llm = OllamaLLM(temperature = 0, model=\"gemma3:12b\")\n",
    "\n",
    "#output parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "#chain\n",
    "llm_chain = prompt | llm | output_parser\n",
    "\n",
    "response = llm_chain.invoke({\"text\": data['content'][0]})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f4b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#뉴스 본문을 입력으로 사용하여 카테고리를 분류하는 함수 \n",
    "def classify_news_category(content):\n",
    "    response = llm_chain.invoke({\"text\": content})\n",
    "    return response\n",
    "\n",
    "#결과 확인 - 테스트를 우해서 첫 3행만 별도로 추출하여 카테고리 분류 \n",
    "df_test['category'] = df_test['content'].apply(classify_news_category)\n",
    "\n",
    "df_test[['content', 'summary', 'keywords', 'category']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama-app-PvdVXOUT-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
